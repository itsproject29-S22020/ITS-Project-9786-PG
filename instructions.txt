Step 1:

video_frame_extraction.py enables you to extract subclips from video folders. 
Use with times.txt file. 

Edit filepaths in code to appropriate file paths. 
Edit video timestamps to subclip files from in seconds
E.g. to subclip video from 00:00:00 to 00:01:15: 
subclipTimes.write("0-10") -> subclipTimes.write("0-75")

Step 2:

Face detection - upload copy.py enables you to detect and crop faces from multiple frames in a folder. 
Edit the filepaths in code to appropriate directory.
Use with haarcascade_frontalface_default.xml

Step 3: 
Load the two separate folders of train & test sets into the googlenet trial for upload.py file by changing the directory of both the image files and the .csv file of labels

Note: The train dataset is too large to be uploaded in one file so it was uploaded in 7 parts. 

#### OTHER UNSUCCESSFUL ATTEMPTS:
alexnet_pytorch_trial -> Develop an algorithm that loads the pre-trained AlexNet model from PyTorch and classifies the images on two classes 0 and 1. However, the two major errors  found which were SSL Error and Epoch hangup were discussed in the report.
pretrained full -> Develop an algorithm that loads the pretrained model (in this example, ResNet50 was used) and classifies the images on two classes 0 and 1. However, CUDA Runtime Error was found when running on a GPU. Research for solutions on these errors were from this site: https://github.com/pytorch/pytorch/issues/21819#event-2418764283
createDataset.py -> Create a custom dataset of images. This file was supposed to load the frame images and the label csv file efficiently as a custom dataset in Pytorch

